---
layout: post
title: Frontier AI bulletin - 15/04/24 to 21/04/24
date: 2024-04-21
description: 
tags: frontier-ai-bulletin
categories: 
---

**Industry**
- 19/04/24: Google Deepmind publish paper (book? It’s 274 pages) on [the ethics of advanced AI assistants](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf) - incredibly detailed and expansive, clearly define their ethical framework, explore lots of different possible futures, identify challenges of measuring impact holistically, and make lots of suggestions (one idea new to me was coordination between assistants acting on behalf of different users)
- 17/04/24: Boston Dynamics [retire hydraulic humanoid robot Atlas, announce electric successor](https://bostondynamics.com/blog/electric-new-era-for-atlas/)
- 15/04/24: Adobe Premiere Pro to [offer integration with third-party AI services from OpenAI, Runway, and Pika](https://www.reuters.com/technology/adobe-explores-openai-partnership-it-adds-ai-video-tools-2024-04-15/) 
  
**Open-source**
- 21/04/24: Github trending for the last week lists [MaxKB](https://github.com/1Panel-dev/MaxKB) (Chinese LLM), [MiniGemini](https://github.com/dvlab-research/MiniGemini) (framework for getting better performance from vision-language models), [whisper.cpp](https://github.com/ggerganov/whisper.cpp) (local speech-to-text), [codellama](https://github.com/meta-llama/codellama) (Llama 2 for code), [llama-recipes](https://github.com/meta-llama/llama-recipes) (Llama 2 fine-tuning scripts), [LibreChat](https://github.com/danny-avila/LibreChat) (local ChatGPT clone), [MuseTalk](https://github.com/TMElyralab/MuseTalk) (image-and-audio-to-video lipsyncing), [parler-tts](https://github.com/huggingface/parler-tts) (text-to-speech lib), [aiXcoder-7B](https://github.com/aixcoder-plugin/aiXcoder-7B) (coding LLM), [ragflow](https://github.com/infiniflow/ragflow) (RAG engine), [simple-evals](https://github.com/openai/simple-evals) (set of evaluation benchmarks used by OpenAI to evaluate GPT-4 Turbo) (week-on-week, it looks like Chinese repos are featuring more and more frequently in Github trending)
- 18/04/24: Meta announce 8B- and 70B-parameter versions of Llama 3, 8B-param model surpasses Gemma 7B and Mistral 7B on major benchmarks, 70B model offers comparable performance to Gemini Pro 1.5 and Claude 3 Sonnet (unclear on inference cost), offer sneak-peak at 400B-param model which is still in training, most recent checkpoint’s performance seems to be on par with Claude 3 Opus 
- 18/04/24: In the same announcement, Meta release [Llama Guard 2](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-guard-2/) (input-output classifier) and [CYBERSECEVAL 2](https://ai.meta.com/research/publications/cyberseceval-2-a-wide-ranging-cybersecurity-evaluation-suite-for-large-language-models/) (which includes a load of prompt injection evaluations, break down of attacks tested is on page 6 of paper). They also are using Llama 3 in [Meta’s chat assistant](https://about.fb.com/news/2024/04/meta-ai-assistant-built-with-llama-3/) 

**Academia, Civil Society, and Not-for-profits**
- 21/04/24: 1451 entries in AIAAIC database,  “Texas STAAR automated scoring engine criticized for dumbing down students”, “MEP files lawsuit to release iBorderCtrl lie detection system documents”, “Adobe trained Firefly AI model on competitor images”
- 21/04/24: Center for AI Safety publish blog post [Representation Engineering: A New Way of Understanding Models](https://www.safe.ai/blog/representation-engineering-a-new-way-of-understanding-models) - here “representation engineering” means identifying activations that are correlated with particular answer properties, such as honesty. 
- 15/04/24: Coalition of AI safety researchers led by Abulhair Saparov and Javier Rando publish [big paper]([https://llm-safety-challenges.github.io/challenges_llms.pdf](https://llm-safety-challenges.github.io/challenges_llms.pdf)) identifying foundational AI safety challenges and posing hundreds of research questions.
- 17/04/24: RAND publish report [Using Artificial Intelligence Tools in K-12 Classrooms](https://www.rand.org/pubs/research_reports/RRA956-21.html), found 18% of K-12 public school teachers use AI for teaching, with English and social studies teachers the most likely to use it, most common use was to customize content to fit a target audience, 60% of US school districts plan to have trained teachers about AI use (K-12 means all classes from 5-6 yo to 17-18yo).
- 17/04/24: Epoch publish paper [Chinchilla Scaling: A Replication Attempt](https://epochai.org/blog/chinchilla-scaling-a-replication-attempt) - the “Chinchilla optimal” model size and volume of training data for a given compute budget is described by a 2022 paper - the formula presented in the paper is frequently used by AI engineers to decide what how big a model and how much data to use. This paper challenges the original paper’s assertions about what the relationship is.    
- 15/04/24: Stanford HAI publish [AI Index Report 2024](https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf) - [summary](https://hai.stanford.edu/news/ai-index-state-ai-13-charts)  
- 12/04/24: The Machine Intelligence Research Institute [newsletter is back](https://intelligence.org/2024/04/12/april-2024-newsletter/), refer to their January announcement detailing their new focus on AI regulation and policy that aims at pausing AI development.

**News Outlets & Blogs**
- 19/04/24: [Q1 earnings for Meta, Microsoft, Alphabet due next week](https://www.ft.com/content/e7d5852e-a310-470f-a26e-d31fa205e9a0)    
- 14/04/24: [Humane’s AI pin gets panned](https://www.youtube.com/watch?v=TitZV6k8zfA) 

**Governments**
- 17/04/24: Paul Christiano [announced as Head of AI Safety at US AI Safety Institute](https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/), full leadership team [announced here](https://www.commerce.gov/news/press-releases/2024/04/us-commerce-secretary-gina-raimondo-announces-expansion-us-ai-safety)
* 16/04/24: Mitt Romney and other senators publish [Framework for Mitigating Extreme AI Risks](https://www.romney.senate.gov/romney-reed-moran-king-unveil-framework-to-mitigate-extreme-ai-risks/) to frame future Congressional discussion of AI regulation (surprisingly, makes no reference to US AISI)