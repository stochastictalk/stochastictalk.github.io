---
layout: post
title: Frontier AI bulletin - 01/04/24 to 14/04/24
date: 2024-04-14
description: 
tags: frontier-ai-bulletin
categories: 
---


**Industry**
* 12/04/24: xAI [announce multimodal Grok-1.5v, is comparable to GPT-4V, release 700-record visual understanding dataset RealWorldQA](https://x.ai/blog/grok-1.5v)
* 11/04/24: Cohere announce [new text embedding model Rerank 3](https://txt.cohere.com/rerank-3/) 
* 11/04/24: Meta [release evaluation dataset Open-vocabulary Embodied Question Answering (OpenEQA)](https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/), consisting of scans+videos paired with questions about spatial understanding, object recognition and similar. Authors test SOTA vision-language models and find they scarcely outperform language-only models.
* 10/04/24: [Adobe offering photographers cash to gather video data documenting everyday actions](https://www.bloomberg.com/news/articles/2024-04-10/adobe-is-buying-video-clips-for-3-per-minute-to-build-ai-model) 
* 10/04/24: Meta [announce a new chip for their ranking and recommendation workloads](https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/), indicate ambition to tailor it to generative AI workloads, mention they've designed it to be complimentary to commercial GPUs, don't say they plan to make it available outside of Meta any time soon
* 09/04/24: Anthropic publish [paper on measuring the persuasiveness of large language models](https://www.anthropic.com/research/measuring-model-persuasiveness), finds that arguments written by Claude 3 Opus are about as persuasive as those written by people, and that logical and deceptive arguments were slightly more persuasive than emotional arguments. Also find automated grading of persuasiveness is rubbish.
* 08/04/24: [Apple Machine Learning Research publish paper demonstrating a model designed for visual understanding of mobile user interfaces](https://arxiv.org/pdf/2404.05719.pdf)
* 08/04/24: Sam Altman and Jony Ive rumoured to be looking for funding for their [AI-powered personal device startup](https://arstechnica.com/gadgets/2024/04/apples-jony-ive-and-openais-sam-altman-team-up-for-ai-device-startup/) 
* 08/04/24: [Stability AI release Stable LM 2B for non-commercial use](https://stability.ai/news/introducing-stable-lm-2-12b), weirdly don't compare it to SOTA proprietary models
* 07/04/24: [Newly created Microsoft AI announce London office and that they'll be hiring over the next few months](https://blogs.microsoft.com/blog/2024/04/07/announcing-new-microsoft-ai-hub-in-london/)
* 05/04/24: [Meta plan to introduce user-disclosed "made with AI" labels on content](https://www.axios.com/2024/04/05/meta-broader-ai-labeling), similar to [Youtube's decision a few weeks ago](https://www.theverge.com/2024/3/18/24104743/youtube-ai-generated-content-disclosure-label)
* 04/04/24: [OpenAI says 600k+ users have signed up to ChatGPT Enterprise](https://www.bloomberg.com/news/articles/2024-04-04/openai-sees-tremendous-growth-in-corporate-version-of-chatgpt)
* 04/04/24: Cohere [announce Command R+](https://txt.cohere.com/command-r-plus-microsoft-azure/), offers comparable performance to GPT-4 Turbo at a lower price point, take note - really informative product launch page
* 04/04/24: [OpenAI launch new features for their fine-tuning API that give devs greater visibility and control over model fine-tuning, formalise their "assisted fine-tuning" consulting offering](https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program) 
* 03/04/24: OpenAI [introduce tools to ChatGPT for editing generated images, initially available to Plus subscribers and business users only](https://www.axios.com/2024/04/03/chatgpt-dalle-openai-editing-images)
* 03/04/24: Stability AI [announce and make available proprietary music generation model Stable Audio 2.0](https://stability.ai/news/stable-audio-2-0), to my ears good enough for ads but not for listening for joy
* 02/04/24: AI-assisted software dev company [Replit run their second developer day](https://blog.replit.com/teams-beta)
* 02/04/24: Anthropic publish [paper outlining that large-language models can be jailbroken by providing many in-context examples of the target behaviour, outline a mitigation that involves prepending and appending a warning to the model that it should avoid being jailbroken](https://www.anthropic.com/research/many-shot-jailbreaking)
* 01/04/24: [OpenAI announce that they are rolling out no-signup ChatGPT](https://openai.com/blog/start-using-chatgpt-instantly)
* 29/03/24: Apple Machine Learning Research [publish a paper on automatically resolving user references to on-screen items](https://arxiv.org/pdf/2403.20329.pdf). Good demo of addressing a well-scoped problem that would meaningfully change user interaction. Also a good demo of GPT-4 beating even custom-built models on novel tasks.  

**Open-source**
* 15/04/24: Eleuther [open-source LLM the Pile-T5](https://blog.eleuther.ai/pile-t5/)
* 14/04/24: Github trending lists [aixcoder](https://github.com/aixcoder-plugin/aiXcoder-7B) (LLM for code), [STORM](https://github.com/stanford-oval/storm) (topic-to-wikipedia article agent), [parler-tts](https://github.com/huggingface/parler-tts) (text-to-speech training and inference codebase), [Fooocus](https://github.com/lllyasviel/Fooocus) (Gradio GUI for text-to-image), [llm-universe](https://github.com/datawhalechina/llm-universe) (Chinese LLM framework), [MagicTime](https://github.com/PKU-YuanGroup/MagicTime) (text-to-video for timelapse videos)   
* 10/04/24: Mistral [open-source large language model Mixtral-8x22B](https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1-4bit)
* 09/04/24: [Google Deepmind release CodeGemma and lower-resource RecurrentGemma variants of open-source Gemma language models](https://developers.googleblog.com/2024/04/gemma-family-expands.html)
* 09/04/24: [Meta confirm that they'll release Llama 3 within the next month](https://techcrunch.com/2024/04/09/meta-confirms-that-its-llama-3-open-source-llm-is-coming-in-the-next-month/), with small versions coming in the next week
 
**Academia, Civil Society, and Not-for-profits**
* 05/04/24: Coalition of AI policy researchers publish paper [Responsible Reporting for Frontier AI Development](https://arxiv.org/pdf/2404.02675.pdf), outlining the information they recommend AI developers disclose to governments (system specification, description of testing, risk assessment, indication of safeguards and other mitigations)       
* 03/04/24: The Institute for AI Policy publish [AI-Relevant Regulatory Precedents: A Systematic Search Across All Federal Agencies](https://www.iaps.ai/research/ai-relevant-regulatory-precedent)  
* 14/04/24: [1445 entries in AIAAIC database](https://docs.google.com/spreadsheets/d/1Bn55B4xz21-_Rgdr8BBb2lt0n_4rzLGxFADMlVW0PYI/edit#gid=888071280), "Alberta Party endorses itself using deepfake video", "YouTube inserts explicit captions into kids' videos", "Synthesia AI video generation", "Robot crushes Thai factory worker to death"
* 10/04/24: The Center for AI Safety publish [blog post "A Bird's Eye View of the ML Field"](https://www.safe.ai/blog/a-birds-eye-view-of-the-ml-field) (long but thoughtful and entertaining, the motivated reasoning section is deadly) 
* 05/04/24: Epoch release a [report analysing trends in compute-intensiveness of models, along with a dataset listing 80 compute-intensive models](https://epochai.org/blog/tracking-compute-intensive-ai-models)
* 05/04/24: [AI Incidents Database publish their March round-up](https://incidentdatabase.ai/blog/incident-report-2024-march/), mostly flag deepfake incidents 
* 04/04/24: Center for Security and Emerging Technology publish [English translation of Chinese gov foundation model safety standard "Basic Safety Requirements for Generative AI Services"](https://cset.georgetown.edu/publication/china-safety-requirements-for-generative-ai-final/) - extremely interesting, contains very specific requirements for model training data and evaluations
* 03/04/24: Stanford Human-Centred AI [blog and overview](https://hai.stanford.edu/news/where-generative-ai-meets-human-rights) of February conference on generative AI and human rights, cite UN's B-Tech Project outlining [policy recommendations for governing generative AI](https://www.ohchr.org/sites/default/files/documents/issues/business/b-tech/recommendations/advancing-responsible-development-and-deployment-of-GenAI.pdf) and [taxonomy of human rights risks connected to generative AI](https://www.ohchr.org/sites/default/files/documents/issues/business/b-tech/taxonomy-GenAI-Human-Rights-Harms.pdf)
* 28/02/24: [Security researcher spots a hallucinated dependency in an Alibaba package's source code, creates it to illustrate the possibility of a supply-chain attack](https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/)

**News Outlets & Blogs**
* 04/04/24: SÃ©b Krier blogs [Beyond One-size Fits All Fairness](https://www.aipolicyperspectives.com/p/beyond-one-size-fits-all-fairness?lli=1&utm_source=profile&utm_medium=reader2), advocating for mostly pluralistic models

**Governments**
* 12/04/24: Republic of Korea [announce Seoul AI Summit for 21-22 May](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park) 
 * 11/04/24: [UK Competition and Markets Authority state they have informed concerns about six-firm AI oligopoly](https://www.gov.uk/government/news/cma-outlines-growing-concerns-in-markets-for-ai-foundation-models) 
 * 10/04/24: [US and Japan announce $110m stumped up by big tech to fund AI research collabs between US and Japanese universities](https://www.bloomberg.com/news/articles/2024-04-10/biden-kishida-meeting-ai-research-funded-by-amazon-nvidia-announced)
 * 10/04/24: RAND [submit written evidence to UK parliament](https://committees.parliament.uk/writtenevidence/127769/html) assessing and making recommendations on AI in the UK's military - may be worth reading even if you have no interest in defence, as it provides a succinct overview of the strategic positioning and statistics of the UK's investment and AI industry 
 * 05/04/24: EU and US reaffirm collaborative "risk-based approach" to AI development at sixth meeting of EU-US Trade and Technology Council, including cooperation between European AI Office and US AISI in implementing the TTC's [Joint Roadmap on Evaluation and Measurement Tools for Trustworthy AI and Risk Management](https://digital-strategy.ec.europa.eu/en/library/ttc-joint-roadmap-trustworthy-ai-and-risk-management).
 * 04/04/24: Microsoft's Threat Intelligence [publish a white paper describing the recent CCP's international information operations, including its use of AI-generated content](https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/MTAC-East-Asia-Report.pdf)
 * 02/04/24: [UK and US AI Safety Institutes sign Memorandum of Understanding outlining that they will collaborate and aim for interoperability](https://www.gov.uk/government/news/uk-united-states-announce-partnership-on-science-of-ai-safety)
 * 02/04/24: RAND publish [report for Department of Homeland Security assessing risk to critical infrastructure over the next decade from incorporating AI](https://www.rand.org/pubs/research_reports/RRA2873-1.html)