---
layout: post
title: Frontier AI bulletin - 22/04/24 to 12/05/24
date: 2024-05-12
description: 
tags: frontier-ai-bulletin
categories: 
---

It’s been a busy few weeks with moving house, so I’m a bit behind and this is slightly less thorough than usual. Usual service will resume next Sunday!

**Industry**
* 08/05/24: Google Deepmind [release AlphaFold 3](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/) for predicting the structure of proteins and how they interact
* 08/05/24: OpenAI publish blog post introducing a [specification of how they want their models to behave](https://openai.com/index/introducing-the-model-spec/), spec itself is [here](https://cdn.openai.com/spec/model-spec-2024-05-08.html) 
* 07/05/24: OpenAI announce they’re joining the steering committee of the Coalition for Content Provenance and Authenticity, remind everyone that they’re working on metadata and watermarking for tagging synthetic content, open access to evaluating their classifier for detecting synthetic imagery
* 03/05/24: OpenAI publish blog post [Reimagining Secure Infrastructure for Advanced AI](https://openai.com/index/reimagining-secure-infrastructure-for-advanced-ai/), outline six principles for improving security of advanced AI systems (use cryptographically trusted computing; disjoint physical networks and sets of management personnel; better operational and physical security; security audits; automated security; redundancy)  

**Open-source**
* 12/05/24: Github trending for the last week lists [pykan](https://github.com/KindXiaoming/pykan) (Kolmogorov-Arnold networks), [openui](https://github.com/wandb/openui) (W&B GUI generator), [gpt-researcher](https://github.com/assafelovic/gpt-researcher) (local GPT to help with web research), [MemGPT](https://github.com/cpacker/MemGPT) (agent framework), [maestro](https://github.com/Doriandarko/maestro) (agent framework), [llm2vec](https://github.com/McGill-NLP/llm2vec) (converts LLM into a text encoder), [perplexica](https://github.com/ItzCrazyKns/Perplexica) (open-source Perplexity)  

**Academia, Civil Society, and Not-for-profits**
* 12/05/24: [AIAAIC database](https://docs.google.com/spreadsheets/d/1Bn55B4xz21-_Rgdr8BBb2lt0n_4rzLGxFADMlVW0PYI/edit#gid=888071280) contains 1480 entries, most recent being “Portugal bans Worldcoin for 90 days for jeopardising citizen privacy”, “AI researcher claims Amazon ignored copyright rules”, “WildBrain accuses Kartoon Studios of IP infringement over Gadget A.I.”
* 10/05/24: The Center for AI Safety release new textbook and online course [“AI Safety, Ethics, and Society”](https://www.safe.ai/blog/ai-safety-ethics-and-society) 
* 07/05/24: AI Incidents Database publish their [April round-up](https://incidentdatabase.ai/blog/incident-report-2024-april/), highlight “Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action”, “Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director”, “Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries” 
* ??/05/24: Center for Emerging Technology and Security publish briefing paper for NCSC, [“Autonomous Cyber Defense Phase II”](https://cetas.turing.ac.uk/publications/autonomous-cyber-defence-autonomous-agents) 
* 06/05/24: Institute for AI Policy and Strategy publish a [report on location verification for AI chips](https://static1.squarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/6639251ef53824001b5a657c/1715021087537/Location+Verification+for+AI+Chips.pdf) 
* 02/05/24: Institute for AI Policy and Strategy publish an [analysis of what AI risk information it’s wise to discuss via informal dialogue between non-state actors](https://static1.squarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/6633b93601a0553b73d56095/1714665783885/%5BFinal%5D+Topics+for+track+IIs.pdf)
* 02/05/24: Stanford HAI releases policy brief [Escalation Risks from LLMs in Military and Diplomatic Contexts](https://hai.stanford.edu/policy-brief-escalation-risks-llms-military-and-diplomatic-contexts) 
* 02/04/25: Center for Security and Emerging Technology publish [translation of draft China AI law](https://cset.georgetown.edu/publication/china-ai-law-draft/) 
* 30/04/24: Insitute for AI Policy and Strategy publish a [breakdown of responsible AI funding in Biden’s 24/25 budget](https://www.iaps.ai/s/AI-Highlights-from-the-Biden-Administrations-FY2025-Budget-Proposal.pdf) 
* 24/04/24: Group of academics publish [dataset and analysis that links demographic subgroups to the types of feedback they give on LLM performance](https://arxiv.org/pdf/2404.16019) - this is so interesting, it’s like having a representative sample of what people Google, see the chart on page 11

**Governments**
* 10/05/24: [UK’s AI Safety Institute open-sources code library for building safety evaluations](https://www.gov.uk/government/news/ai-safety-institute-releases-new-ai-safety-evaluations-platform)
* 29/04/24: [NIST launch generative AI detection challenge](https://ai-challenges.nist.gov/genai)